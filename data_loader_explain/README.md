# NJF ToyArm é€‚é… 4DGaussians - æ“ä½œæ‰‹å†Œ

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ Neural-Jacobian-Field (NJF) ToyArm æ•°æ®é›†è®­ç»ƒ 4DGaussiansï¼Œæä¾›ä¸¤ç§æ–¹æ¡ˆåŠå…¶æ‰€éœ€çš„ä»£ç ä¿®æ”¹å’Œæ“ä½œæ­¥éª¤ã€‚

---

## ğŸ“‹ æ ¸å¿ƒå†…å®¹æ¦‚è§ˆ

### ä¸¤ç§é€‚é…æ–¹æ¡ˆ

| æ–¹æ¡ˆ | æ ¸å¿ƒæ€æƒ³ | ä»£ç ä¿®æ”¹ | é€‚ç”¨åœºæ™¯ |
|-----|---------|---------|---------|
| **æ–¹æ¡ˆä¸€ï¼šæ•°æ®è½¬æ¢** | è½¬æ¢NJFæ ¼å¼ä¸º4DGaussiansæ ¼å¼ | âŒ æ— éœ€ä¿®æ”¹ | å¿«é€Ÿæµ‹è¯•ã€ä¸€æ¬¡æ€§ä½¿ç”¨ |
| **æ–¹æ¡ˆäºŒï¼šä»£ç é›†æˆ** | ä¿®æ”¹4DGaussiansç›´æ¥è¯»å–NJF | âœ… éœ€è¦ä¿®æ”¹ | é¢‘ç¹ä½¿ç”¨ã€è‡ªå®šä¹‰éœ€æ±‚ |

### æ–°å¢åŠŸèƒ½ï¼šå…³èŠ‚ä½ç½®å·®å€¼ u

ä¸¤ç§æ–¹æ¡ˆéƒ½ä¼šè‡ªåŠ¨è®¡ç®—å…³èŠ‚ä½ç½®å·®å€¼ `u`ï¼š
- **u = current_joint_pos - previous_joint_pos** (æ¯ä¸ªç›¸æœºç‹¬ç«‹è®¡ç®—)
- **ç¬¬ä¸€å¸§**: u = [0, 0, 0, 0, 0, 0]
- **ç”¨é€”**: å¯ä½œä¸ºæ¡ä»¶ä¿¡å·ç”¨äºæ§åˆ¶åŒ–4DGaussiansè®­ç»ƒ

---

## ğŸš€ æ–¹æ¡ˆä¸€ï¼šæ•°æ®è½¬æ¢ï¼ˆæ¨èæ–°æ‰‹ï¼‰

### éœ€è¦çš„æ–‡ä»¶

```
4DGaussians/
â””â”€â”€ convert_njf_to_4dgs.py    # æ•°æ®è½¬æ¢è„šæœ¬ï¼ˆå·²æä¾›ï¼‰
```

### ä»£ç ä¿®æ”¹

**âœ… æ— éœ€ä»»ä½•ä»£ç ä¿®æ”¹ï¼**

### æ“ä½œæ­¥éª¤

#### ç¬¬ä¸€æ­¥ï¼šè½¬æ¢æ•°æ®

```bash
cd d:\Codee\4DGaussians

python convert_njf_to_4dgs.py \
    --input d:\Codee\neural-jacobian-field\data\toyarm\transforms.json \
    --output d:\Codee\4DGaussians\data\toyarm_converted \
    --train_split 0.9
```

**å‚æ•°è¯´æ˜**ï¼š
- `--input`: NJFçš„transforms.jsonè·¯å¾„
- `--output`: è¾“å‡ºç›®å½•ï¼ˆæ–°å»ºï¼Œä¸ä¼šè¦†ç›–åŸå§‹æ•°æ®ï¼‰
- `--train_split`: è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.9ï¼‰

**ç”Ÿæˆçš„æ–‡ä»¶**ï¼š
```
data/toyarm_converted/
â”œâ”€â”€ transforms_train.json   # è®­ç»ƒé›†ï¼ˆå«uå­—æ®µï¼‰
â”œâ”€â”€ transforms_test.json    # æµ‹è¯•é›†ï¼ˆå«uå­—æ®µï¼‰
â””â”€â”€ fused.ply              # åˆå§‹ç‚¹äº‘
```

**transforms.json æ ¼å¼ç¤ºä¾‹**ï¼š
```json
{
    "camera_angle_x": 0.857,
    "frames": [
        {
            "file_path": "view_0/rgb/00000_00000.png",
            "transform_matrix": [[...], ...],
            "time": 0.0,
            "u": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  // å…³èŠ‚ä½ç½®å·®å€¼
            "joint_pos": [-6.3, -9.82, -8.65, -11.0, 1.03, 6.01],
            "sample_idx": 0,
            "camera_idx": 0
        }
    ]
}
```

#### ç¬¬äºŒæ­¥ï¼šåˆ›å»ºå›¾åƒç¬¦å·é“¾æ¥

```powershell
cd d:\Codee\4DGaussians\data\toyarm_converted

# ä¸ºæ¯ä¸ªè§†è§’åˆ›å»ºç¬¦å·é“¾æ¥
0..11 | ForEach-Object { 
    cmd /c mklink /J "view_$_" "d:\Codee\neural-jacobian-field\data\toyarm\view_$_" 
}
```

**æˆ–è€…**å¤åˆ¶å›¾åƒï¼ˆå ç”¨æ›´å¤šç©ºé—´ï¼‰ï¼š
```bash
python convert_njf_to_4dgs.py --input ... --output ... --copy_images
```

#### ç¬¬ä¸‰æ­¥ï¼šè®­ç»ƒ

```bash
python train.py \
    -s d:\Codee\4DGaussians\data\toyarm_converted \
    -m d:\Codee\4DGaussians\output\toyarm_exp1 \
    --eval \
    --iterations 7000
```

#### ç¬¬å››æ­¥ï¼šæ¸²æŸ“

```bash
# æ¸²æŸ“è®­ç»ƒé›†
python render.py -m d:\Codee\4DGaussians\output\toyarm_exp1

# æ¸²æŸ“æµ‹è¯•é›†
python render.py -m d:\Codee\4DGaussians\output\toyarm_exp1 --skip_train
```

### éªŒè¯

```bash
# æ£€æŸ¥uå­—æ®µ
python -c "import json; data=json.load(open('data/toyarm_converted/transforms_train.json')); print('First frame u:', data['frames'][0]['u'])"

# æ£€æŸ¥å¸§æ•°
python -c "import json; print('Train frames:', len(json.load(open('data/toyarm_converted/transforms_train.json'))['frames']))"
```

---

## âš™ï¸ æ–¹æ¡ˆäºŒï¼šä»£ç é›†æˆï¼ˆæ¨èé«˜çº§ç”¨æˆ·ï¼‰

### éœ€è¦çš„æ–‡ä»¶

```
4DGaussians/
â”œâ”€â”€ scene/
â”‚   â”œâ”€â”€ njf_toyarm_loader.py       # NJFæ•°æ®åŠ è½½å™¨ï¼ˆå·²æä¾›ï¼‰
â”‚   â”œâ”€â”€ dataset_readers.py         # éœ€è¦ä¿®æ”¹
â”‚   â””â”€â”€ __init__.py                # å¯èƒ½éœ€è¦ä¿®æ”¹
â””â”€â”€ arguments/__init__.py          # å¯èƒ½éœ€è¦ä¿®æ”¹
```

### ä»£ç ä¿®æ”¹æ¸…å•

#### ä¿®æ”¹ 1: å¤åˆ¶æ•°æ®åŠ è½½å™¨

å°†æä¾›çš„ `njf_toyarm_loader.py` æ–‡ä»¶å¤åˆ¶åˆ°ï¼š
```
d:\Codee\4DGaussians\scene\njf_toyarm_loader.py
```

**æ–‡ä»¶åŠŸèƒ½**ï¼š
- å®šä¹‰ `CameraInfoWithU` ç±»ï¼ˆåŒ…å«uå’Œjoint_poså­—æ®µï¼‰
- å®ç° `readNJFTransforms()` å‡½æ•°ï¼ˆè¯»å–NJFæ ¼å¼å¹¶è®¡ç®—uï¼‰
- å®ç° `readNJFSceneInfo()` å‡½æ•°ï¼ˆåœºæ™¯åŠ è½½å…¥å£ï¼‰

#### ä¿®æ”¹ 2: scene/dataset_readers.py

åœ¨æ–‡ä»¶**å¼€å¤´**æ·»åŠ å¯¼å…¥ï¼ˆçº¦ç¬¬30è¡Œï¼‰ï¼š

```python
from scene.gaussian_model import BasicPointCloud
from utils.general_utils import PILtoTorch
from tqdm import tqdm
from scene.njf_toyarm_loader import readNJFSceneInfo  # â† æ–°å¢è¿™ä¸€è¡Œ
```

åœ¨æ–‡ä»¶**æœ«å°¾**ä¿®æ”¹å­—å…¸ï¼ˆçº¦ç¬¬679è¡Œï¼‰ï¼š

```python
sceneLoadTypeCallbacks = {
    "Colmap": readColmapSceneInfo,
    "Blender" : readNerfSyntheticInfo,
    "dynerf" : readdynerfInfo,
    "nerfies": readHyperDataInfos,
    "PanopticSports" : readPanopticSportsinfos,
    "MultipleView": readMultipleViewinfos,
    "NJF": readNJFSceneInfo,  # â† æ–°å¢è¿™ä¸€è¡Œ
}
```

#### ä¿®æ”¹ 3: arguments/__init__.pyï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦å‘½ä»¤è¡Œå‚æ•°æ”¯æŒï¼Œåœ¨ `ModelParams` ç±»ä¸­æ·»åŠ ï¼š

```python
class ModelParams:
    def __init__(self, parser, sentinel=False):
        # ... ç°æœ‰ä»£ç  ...
        
        self.parser.add_argument('--dataset_type', type=str, 
                                default='Colmap',
                                choices=['Colmap', 'Blender', 'dynerf', 
                                        'nerfies', 'PanopticSports', 
                                        'MultipleView', 'NJF'],  # â† æ·»åŠ 'NJF'
                                help='Type of dataset to load')
```

#### ä¿®æ”¹ 4: scene/__init__.pyï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦è‡ªåŠ¨æ£€æµ‹ï¼Œåœ¨ `Scene` ç±»çš„ `__init__` æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
class Scene:
    def __init__(self, args, gaussians, load_iteration=None, shuffle=True, resolution_scales=[1.0]):
        # ... ç°æœ‰ä»£ç  ...
        
        # åœ¨æ•°æ®é›†ç±»å‹æ£€æµ‹éƒ¨åˆ†æ·»åŠ 
        if os.path.exists(os.path.join(args.source_path, "sparse")):
            scene_info = sceneLoadTypeCallbacks["Colmap"](...)
        elif os.path.exists(os.path.join(args.source_path, "transforms_train.json")):
            scene_info = sceneLoadTypeCallbacks["Blender"](...)
        elif os.path.exists(os.path.join(args.source_path, "transforms.json")):
            # â† æ–°å¢ï¼šæ£€æµ‹NJFæ ¼å¼
            print("Found NJF transforms.json, using NJF loader")
            scene_info = sceneLoadTypeCallbacks["NJF"](
                args.source_path, args.white_background, args.eval
            )
        else:
            # ... å…¶ä»–æ£€æµ‹ ...
```

### æ“ä½œæ­¥éª¤

#### ç¬¬ä¸€æ­¥ï¼šéªŒè¯æ•°æ®åŠ è½½

```python
# æµ‹è¯•åŠ è½½å™¨
from scene.njf_toyarm_loader import readNJFSceneInfo

scene_info = readNJFSceneInfo(
    "d:/Codee/neural-jacobian-field/data/toyarm", 
    white_background=False, 
    eval=True
)

print(f"Train cameras: {len(scene_info.train_cameras)}")
print(f"Test cameras: {len(scene_info.test_cameras)}")
print(f"Point cloud points: {scene_info.point_cloud.points.shape}")
```

#### ç¬¬äºŒæ­¥ï¼šç›´æ¥è®­ç»ƒ

```bash
python train.py \
    -s d:\Codee\neural-jacobian-field\data\toyarm \
    --dataset_type NJF \
    -m d:\Codee\4DGaussians\output\toyarm_exp1 \
    --eval \
    --iterations 7000
```

**æˆ–è€…**ï¼ˆå¦‚æœå®ç°äº†è‡ªåŠ¨æ£€æµ‹ï¼‰ï¼š

```bash
python train.py \
    -s d:\Codee\neural-jacobian-field\data\toyarm \
    -m d:\Codee\4DGaussians\output\toyarm_exp1 \
    --eval
```

#### ç¬¬ä¸‰æ­¥ï¼šæ¸²æŸ“

```bash
python render.py -m d:\Codee\4DGaussians\output\toyarm_exp1
```

### ä»£ç ä¿®æ”¹æ€»ç»“

| æ–‡ä»¶ | ä¿®æ”¹ç±»å‹ | å¿…éœ€æ€§ | ä¿®æ”¹å†…å®¹ |
|-----|---------|-------|---------|
| `scene/njf_toyarm_loader.py` | æ–°å¢æ–‡ä»¶ | âœ… å¿…éœ€ | å¤åˆ¶æä¾›çš„æ–‡ä»¶ |
| `scene/dataset_readers.py` | ä¿®æ”¹ | âœ… å¿…éœ€ | æ·»åŠ å¯¼å…¥å’Œæ³¨å†ŒNJF |
| `arguments/__init__.py` | ä¿®æ”¹ | âš ï¸ å¯é€‰ | æ·»åŠ dataset_typeå‚æ•° |
| `scene/__init__.py` | ä¿®æ”¹ | âš ï¸ å¯é€‰ | æ·»åŠ è‡ªåŠ¨æ£€æµ‹é€»è¾‘ |

---

## ğŸ” å…³äºå…³èŠ‚ä½ç½®å·®å€¼ u

### è®¡ç®—é€»è¾‘

```python
# ä¼ªä»£ç 
prev_joint_pos_per_camera = {}  # æ¯ä¸ªç›¸æœºç‹¬ç«‹è·Ÿè¸ª

for frame in sorted_frames:  # æŒ‰(time, camera_idx)æ’åº
    camera_idx = frame['camera_idx']
    curr_joint_pos = frame['joint_pos']
    
    if camera_idx in prev_joint_pos_per_camera:
        u = curr_joint_pos - prev_joint_pos_per_camera[camera_idx]
    else:
        u = [0, 0, 0, 0, 0, 0]  # ç¬¬ä¸€å¸§
    
    frame['u'] = u
    prev_joint_pos_per_camera[camera_idx] = curr_joint_pos
```

### æ•°æ®æ ¼å¼

**æ–¹æ¡ˆä¸€**ï¼šuåœ¨JSONæ–‡ä»¶ä¸­
```json
{
    "frames": [
        {
            "u": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  // ç¬¬ä¸€å¸§
            "joint_pos": [-6.3, -9.82, -8.65, -11.0, 1.03, 6.01]
        },
        {
            "u": [2.45, 1.23, -0.56, 0.89, -0.12, 0.34],  // åç»­å¸§
            "joint_pos": [-3.85, -8.59, -9.21, -10.11, 0.91, 6.35]
        }
    ]
}
```

**æ–¹æ¡ˆäºŒ**ï¼šuåœ¨CameraInfoå¯¹è±¡ä¸­
```python
class CameraInfoWithU(NamedTuple):
    uid: int
    R: np.array
    T: np.array
    # ... å…¶ä»–å­—æ®µ ...
    u: Optional[np.array]  # å…³èŠ‚ä½ç½®å·®å€¼
    joint_pos: Optional[np.array]  # åŸå§‹å…³èŠ‚ä½ç½®
```

### åœ¨4DGaussiansä¸­ä½¿ç”¨u

éœ€è¦ä¿®æ”¹Cameraç±»å’Œè®­ç»ƒå¾ªç¯ä»¥ä½¿ç”¨uä½œä¸ºæ¡ä»¶ä¿¡å·ã€‚è¯¦è§ï¼š`å…³èŠ‚ä½ç½®å·®å€¼uçš„ä½¿ç”¨è¯´æ˜.md`

---

## ğŸ“Š ä¸¤ç§æ–¹æ¡ˆå¯¹æ¯”

### è¯¦ç»†å¯¹æ¯”

| ç»´åº¦ | æ–¹æ¡ˆä¸€ï¼šæ•°æ®è½¬æ¢ | æ–¹æ¡ˆäºŒï¼šä»£ç é›†æˆ |
|-----|----------------|-----------------|
| **å®ç°æ—¶é—´** | 5åˆ†é’Ÿ | 30-60åˆ†é’Ÿ |
| **ä¿®æ”¹æ–‡ä»¶æ•°** | 0ä¸ª | 2-4ä¸ª |
| **ä»£ç ç¨³å®šæ€§** | â­â­â­ é«˜ | â­â­ ä¸­ |
| **æ•°æ®å­˜å‚¨** | éœ€è¦é¢å¤–ç©ºé—´ | ç›´æ¥è¯»å–åŸå§‹æ•°æ® |
| **çµæ´»æ€§** | â­â­ ä¸­ | â­â­â­ é«˜ |
| **è°ƒè¯•éš¾åº¦** | â­ ä½ | â­â­â­ é«˜ |
| **ç‰ˆæœ¬å…¼å®¹** | ä¸å—4DGaussiansæ›´æ–°å½±å“ | å¯èƒ½éœ€è¦éš4DGaussiansæ›´æ–° |

### é€‰æ‹©å»ºè®®

**é€‰æ‹©æ–¹æ¡ˆä¸€**ï¼Œå¦‚æœï¼š
- âœ… ç¬¬ä¸€æ¬¡ä½¿ç”¨NJFæ•°æ®
- âœ… æƒ³å¿«é€Ÿæµ‹è¯•å¯è¡Œæ€§
- âœ… ä¸æƒ³ä¿®æ”¹4DGaussiansä»£ç 
- âœ… ä¸€æ¬¡æ€§æˆ–å¶å°”ä½¿ç”¨

**é€‰æ‹©æ–¹æ¡ˆäºŒ**ï¼Œå¦‚æœï¼š
- âœ… éœ€è¦é¢‘ç¹ä½¿ç”¨NJFæ•°æ®
- âœ… æœ‰å¤šä¸ªNJFæ•°æ®é›†
- âœ… éœ€è¦è‡ªå®šä¹‰æ•°æ®åŠ è½½é€»è¾‘
- âœ… ç†Ÿæ‚‰4DGaussiansä»£ç ç»“æ„

**æ¨èå·¥ä½œæµ**ï¼šå…ˆç”¨æ–¹æ¡ˆä¸€æµ‹è¯•ï¼Œç¡®è®¤å¯è¡Œåå†è€ƒè™‘æ–¹æ¡ˆäºŒ

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: æ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶

**æ–¹æ¡ˆä¸€è§£å†³**ï¼š
```bash
# ä½¿ç”¨--copy_imageså‚æ•°
python convert_njf_to_4dgs.py --input ... --output ... --copy_images

# æˆ–åˆ›å»ºç¬¦å·é“¾æ¥
cd data/toyarm_converted
cmd /c mklink /J view_0 d:\Codee\neural-jacobian-field\data\toyarm\view_0
```

**æ–¹æ¡ˆäºŒè§£å†³**ï¼šç¡®ä¿transforms.jsonä¸­çš„file_pathæ˜¯ç›¸å¯¹äºæ•°æ®é›†æ ¹ç›®å½•çš„æ­£ç¡®è·¯å¾„

### Q2: ç›¸æœºè§†è§’ä¸å¯¹/åœºæ™¯å€’ç½®

**æ–¹æ¡ˆä¸€è§£å†³**ï¼š
```bash
python convert_njf_to_4dgs.py --input ... --output ... --coord_transform opencv_to_opengl
```

**æ–¹æ¡ˆäºŒè§£å†³**ï¼šåœ¨`njf_toyarm_loader.py`ä¸­å–æ¶ˆåæ ‡è½¬æ¢æ³¨é‡Š
```python
# æ‰¾åˆ°è¿™è¡Œå¹¶å–æ¶ˆæ³¨é‡Š
c2w[:3, 1:3] *= -1  # åæ ‡ç³»è½¬æ¢
```

### Q3: è®­ç»ƒå¾ˆæ…¢/å†…å­˜ä¸å¤Ÿ

```bash
# å‡å°‘æ•°æ®é‡
python convert_njf_to_4dgs.py --input ... --output ... --train_split 0.5

# å‡å°‘è¿­ä»£æ¬¡æ•°
python train.py ... --iterations 3000

# é™ä½å›¾åƒåˆ†è¾¨ç‡ï¼ˆä¿®æ”¹loaderä»£ç ï¼‰
image = PILtoTorch(image, (400, 400))  # æ”¹ä¸ºæ›´å°å°ºå¯¸
```

### Q4: å¦‚ä½•éªŒè¯uçš„æ­£ç¡®æ€§

```python
import json
import numpy as np

data = json.load(open('data/toyarm_converted/transforms_train.json'))

# æŒ‰cameraåˆ†ç»„
frames_by_camera = {}
for frame in data['frames']:
    cam_idx = frame['camera_idx']
    if cam_idx not in frames_by_camera:
        frames_by_camera[cam_idx] = []
    frames_by_camera[cam_idx].append(frame)

# éªŒè¯uè®¡ç®—
for cam_idx, frames in frames_by_camera.items():
    frames_sorted = sorted(frames, key=lambda x: x['time'])
    
    for i in range(len(frames_sorted)):
        u = np.array(frames_sorted[i]['u'])
        joint_pos = np.array(frames_sorted[i]['joint_pos'])
        
        if i == 0:
            assert np.allclose(u, 0), f"First frame u should be zero"
        else:
            prev_joint_pos = np.array(frames_sorted[i-1]['joint_pos'])
            expected_u = joint_pos - prev_joint_pos
            assert np.allclose(u, expected_u), f"u mismatch at frame {i}"
    
    print(f"Camera {cam_idx}: âœ… All u values verified")
```

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- **QUICKSTART.md** - å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆ5åˆ†é’Ÿä¸Šæ‰‹ï¼‰
- **NJF_TOYARM_ADAPTATION_GUIDE.md** - æ•°æ®æ ¼å¼è¯¦ç»†å¯¹æ¯”
- **INTEGRATION_GUIDE.md** - æ–¹æ¡ˆäºŒè¯¦ç»†å®ç°æŒ‡å—
- **å…³èŠ‚ä½ç½®å·®å€¼uçš„ä½¿ç”¨è¯´æ˜.md** - uçš„è¯¦ç»†ä½¿ç”¨æ–¹æ³•
- **æ–¹æ¡ˆå¯¹æ¯”è¯´æ˜.md** - ä¸¤ç§æ–¹æ¡ˆçš„æ·±å…¥å¯¹æ¯”

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ¨èï¼šæ–¹æ¡ˆä¸€ 5åˆ†é’Ÿå¿«é€Ÿæµ‹è¯•

```bash
# 1. è½¬æ¢æ•°æ®
python convert_njf_to_4dgs.py \
    --input d:\Codee\neural-jacobian-field\data\toyarm\transforms.json \
    --output d:\Codee\4DGaussians\data\toyarm_test \
    --train_split 0.2

# 2. åˆ›å»ºç¬¦å·é“¾æ¥
cd d:\Codee\4DGaussians\data\toyarm_test
0..11 | ForEach-Object { cmd /c mklink /J "view_$_" "d:\Codee\neural-jacobian-field\data\toyarm\view_$_" }

# 3. å¿«é€Ÿè®­ç»ƒæµ‹è¯•
cd d:\Codee\4DGaussians
python train.py -s data\toyarm_test -m output\test --iterations 500

# 4. æ£€æŸ¥ç»“æœ
ls output\test
```

å¦‚æœæˆåŠŸï¼Œè¿›è¡Œå®Œæ•´è®­ç»ƒï¼š

```bash
# è½¬æ¢å®Œæ•´æ•°æ®
python convert_njf_to_4dgs.py \
    --input d:\Codee\neural-jacobian-field\data\toyarm\transforms.json \
    --output d:\Codee\4DGaussians\data\toyarm_full

# åˆ›å»ºç¬¦å·é“¾æ¥
cd data\toyarm_full
0..11 | ForEach-Object { cmd /c mklink /J "view_$_" "d:\Codee\neural-jacobian-field\data\toyarm\view_$_" }

# å®Œæ•´è®­ç»ƒ
cd d:\Codee\4DGaussians
python train.py -s data\toyarm_full -m output\toyarm_final --eval --iterations 7000

# æ¸²æŸ“
python render.py -m output\toyarm_final
```

---

## ğŸ“ è·å–å¸®åŠ©

1. æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£ï¼ˆæŒ‰éœ€æ±‚é€‰æ‹©ï¼‰
2. æ£€æŸ¥è½¬æ¢è„šæœ¬å¸®åŠ©ï¼š`python convert_njf_to_4dgs.py --help`
3. è¿è¡ŒéªŒè¯è„šæœ¬æµ‹è¯•æ•°æ®æ ¼å¼

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€
